{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a447abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15937313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan  6 05:48:25 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 13.0     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:47:00.0 Off |                   On |\n",
      "| N/A   29C    P0             49W /  400W |                  N/A   |     N/A      Default |\n",
      "|                                         |                        |              Enabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                            |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |                     Memory-Usage |        Vol|        Shared         |\n",
      "|      ID  ID  Dev |                       BAR1-Usage | SM     Unc| CE ENC  DEC  OFA  JPG |\n",
      "|                  |                                  |        ECC|                       |\n",
      "|==================+==================================+===========+=======================|\n",
      "|  0    9   0   0  |            2437MiB /  4864MiB    | 14      0 |  1   0    0    0    0 |\n",
      "|                  |                 2MiB /  8191MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0    9    0             2118      C   /usr/bin/python                        2402MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e36c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6cac0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52327ec",
   "metadata": {},
   "source": [
    "### AutoGrad in PyTorch\n",
    "\n",
    "#### Why AutoGrad is needed?\n",
    "*Calculation of derivatives of nested functions in Neural Networks is very difficult if we have to calculate it everytime...\n",
    "\n",
    "\n",
    "#### What is AutoGrad?\n",
    "* AutoGrad ia a core component of PyTorch that provides automatic differentiation for tensor operations.It enables gradient computation<br>\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5b432ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "# we have to set the requires_grad parameter to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6fbd76cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0966a004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7aa69ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dy/dx\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "57e5f867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27.)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "322aadc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1385e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.sin(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "931c3f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4121, grad_fn=<SinBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1219d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "48ee9f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.4668)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4bdece98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#Inputs\n",
    "\n",
    "X = torch.tensor(6.7)\n",
    "y = torch.tensor(0.0) # true label\n",
    "\n",
    "w = torch.tensor(1.0, requires_grad=True) # weight\n",
    "b = torch.tensor(0.0, requires_grad=True) # bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f31dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss(BCE) for scalar\n",
    "\n",
    "def binary_cross_entropy(prediction, target):\n",
    "    epsilon = 1e-8\n",
    "    prediction = torch.clamp(prediction, epsilon, 1-epsilon) #this bounds our prediction to stay between (epsilon, 1-epsilon)\n",
    "    return -(target * torch.log(prediction) + (1 - target) * torch.log(1 - prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d5a6d9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "\n",
    "z = w * X + b\n",
    "y_pred = torch.sigmoid(z)\n",
    "\n",
    "#calculating loss\n",
    "\n",
    "loss = binary_cross_entropy(y_pred, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "759fa581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7012, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "47bd7dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivatives using AutoGrad\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "264ca2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.6918)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6273e882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9988)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "50b39fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "05990e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6667, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (x ** 2).mean()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6c47025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "55d80f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6667, 1.3333, 2.0000])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad\n",
    "\n",
    "# how 3 gradients.. so y = (x1^2 + x2^2 + x3^2)/3\n",
    "# three gradients are dy/dx1 , dy/dx2, dy/dx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fd266027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CLearing Grad\n",
    "\n",
    "# if we do backward() multiple times these gradient start accumulating ..ie. they start adding up...\n",
    "#so we need to clear them before we do again...a\n",
    "\n",
    "x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2473140b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bc4bb999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#disable gradient tracking.... \n",
    "\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad =True)\n",
    "y = 5 * (x ** 2) + 45\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "696c62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "596c5db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8281528e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' or using torch.no_grad()\\nwith torch.no_grad():\\n    y = 5 * (x ** 2) + 45\\n'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Suppose now we want to make prediction so we dont need gradient tracking...\n",
    "\n",
    "x.requires_grad_(False)\n",
    "\n",
    "\n",
    "# or using a detach function like z = x.detach()\n",
    "''' or using torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    y = 5 * (x ** 2) + 45\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad526874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
