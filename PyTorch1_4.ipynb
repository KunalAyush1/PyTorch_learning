{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOcrQCjsOAgsH/nlEqxBGmE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KunalAyush1/PyTorch_learning/blob/main/PyTorch1_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cyIzfp3763q2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#numpy array to tensors\n",
        "\n",
        "array = np.arange(1.0,8.0)\n",
        "tensor = torch.from_numpy(array)"
      ],
      "metadata": {
        "id": "68WJIy1zAFuk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array.dtype, tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zW5i7pOA3IY",
        "outputId": "7f5c6b1b-00a8-4a04-eb76-5605697df4a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('float64'), torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Note => The dault datatype of numpy array is float64 so while converting to tensor the tensor also becomes flaot64..to change we have to do type conversion\n",
        "\n",
        "'''\n",
        "\n",
        "tensor.type(torch.float16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh1jvW0GBArA",
        "outputId": "670cc212-b8de-40ca-9693-2f3c43a70d70"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQX_QaEmBape",
        "outputId": "800fe733-567b-4c55-d556-d23755f3a0f1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensor to numpy\n",
        "tensor_1 = torch.zeros(5)\n",
        "numpy_tensor = tensor_1.numpy()"
      ],
      "metadata": {
        "id": "mTNyhogtBfIq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_1.dtype, numpy_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s32gG7o6CKIT",
        "outputId": "229e63c5-138d-4c16-b95e-a0cf6ad9d5e6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, dtype('float32'))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility(trying to take random out of random)(Reproducibility means getting the same results when running identical experiments)\n",
        "\n",
        "''' In short how a neural network  works is:\n",
        "\n",
        "start with random numbers -> tensor operations -> update random numbers to try to make them better representations of data->again->again....\n",
        "\n",
        "\n",
        "To reduce the randommness in neural networks and PyTorch comes the concept of a random seed.\n",
        "\n",
        "Essentially what the random seed does is \"flavour\" the randomness.\n",
        "\n",
        "'''\n",
        "\n",
        "random_1 = torch.rand(3,4)\n",
        "random_2 = torch.rand(3,4)\n",
        "print(random_1)\n",
        "print(random_2)\n",
        "# so there is a very little chance that both the tensors will be same or have some same elements\n",
        "print(random_1 == random_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq7oBXzrCPbz",
        "outputId": "ed872ab2-389f-4143-e9f8-b75a4363dc73"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4080, 0.8574, 0.6412, 0.4340],\n",
            "        [0.0863, 0.3435, 0.7337, 0.3607],\n",
            "        [0.1180, 0.3489, 0.0473, 0.1168]])\n",
            "tensor([[0.9888, 0.0301, 0.3223, 0.8383],\n",
            "        [0.6232, 0.4621, 0.4811, 0.7797],\n",
            "        [0.2262, 0.0393, 0.0716, 0.4642]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets make some random but reproducible tensors\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_3 = torch.rand(3,4)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_4 = torch.rand(3,4)\n",
        "print(random_3)\n",
        "print(random_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN-WSh9_EkEb",
        "outputId": "c965005d-cea3-4cdf-8032-d655cf2efda1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Running Tensors and PyTorch objects on the GPUs</h2>\n",
        "*GPUs usage means faster computations thanks to CUDA + NVIDIA + PyTorch working behind the scenes to make everything good\n",
        "\n"
      ],
      "metadata": {
        "id": "PKqrIQ9tOKH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Getting a GPU</h3>\n",
        "1.Easiest is to use Google Colab for a free GPU<br>\n",
        "2.Use your own GPU(takes investmet and steup)<br>\n",
        "3.Use Cloud platforms like AWS , Azure ,etc to access GPUs on a rental basis\n"
      ],
      "metadata": {
        "id": "vSPah0GZHjWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJyqJ0cWOk2n",
        "outputId": "f51f916f-2e8e-4ded-b208-ee3c12622041"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun 20 12:09:33 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check for GPU access\n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-47icGBaPn8b",
        "outputId": "f0b36c75-c69e-4f82-9742-317f4156d7dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8O50jZtEP52w",
        "outputId": "a2bd76d9-9ded-48b0-a9f0-7bd25977ec5c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Count no of GPU\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Phq-pwpFQWSK",
        "outputId": "ac7adc87-cb18-494f-e569-d64bdae30210"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting tensors (and models) on the GPU\n",
        "\n",
        "#Create a tensor on GPU , by default its on CPU..lets see\n",
        "tensor = torch.rand(2,3)\n",
        "tensor.device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCm6zT2uQcxR",
        "outputId": "cb114af1-68de-45b2-df02-775c281d2342"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Move tensor to GPU\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ4cXysYRaEK",
        "outputId": "a0594e9f-2332-47a2-a1fe-bf009e7929f5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note => If tensor is on GPU we cant tranform it to NumPy\n",
        "\n",
        "#Moving back tensors to CPU\n",
        "tensor_on_gpu.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "1hHlpS-DRl-H",
        "outputId": "dd32f1d9-b2cd-4ad5-b178-566245ec63a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-15-988564029.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Moving back tensors to CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtensor_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To fix this we first need to move our tensor back to cpu to trasform it into NumPy\n",
        "\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRvFJAHESMZX",
        "outputId": "3cf60ac1-9a59-4294-d52d-18d4b8ab937d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2877196 , 0.9909075 , 0.9759872 ],\n",
              "       [0.35043877, 0.778977  , 0.62320745]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aJePzPgNSgIZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}